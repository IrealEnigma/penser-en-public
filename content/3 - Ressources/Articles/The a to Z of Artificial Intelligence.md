# The a to Z of Artificial Intelligence

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/media/uploaded_book_covers/profile_1073452/Main-AI-to-Z-illo.jpg)

## Metadata
- Author: [[Time]]
- Full Title: The a to Z of Artificial Intelligence
- Category: #articles
- Summary: A guide to AI jargon for everyone grappling with the power, promise, and perils of artificial intelligence.
- URL: https://time.com/6271657/a-to-z-of-artificial-intelligence/

## Highlights
- **Emergent capabilities**
  When an AI such as a large language model shows unexpected abilities or behaviors that were not programmed into it by its creators, these behaviors are known as “emergent capabilities.” ([View Highlight](https://read.readwise.io/read/01hbnn7hzbbrkgr3rkngyv0q0e))
- New capabilities [tend to emerge](https://cims.nyu.edu/~sbowman/eightthings.pdf) when AIs are trained on more computing power and data. ([View Highlight](https://read.readwise.io/read/01hbnn7pqw43793hrrc7newncq))
- **Foundation model**
  As the AI ecosystem grows, a divide is emerging between large, powerful, general-purpose AIs, known as *Foundation models* or *base models*, and the more specific apps and tools that rely on them. ([View Highlight](https://read.readwise.io/read/01hbnn9b0n5g202ag7rgk0fmz2))
- GPT-3.5, for example, is a foundation model. ([View Highlight](https://read.readwise.io/read/01hbnn9dqy1p9kf5hdkxf8p1ec))
- ChatGPT is a chatbot: an application built over the top of GPT-3.5, with specific fine-tuning to refuse dangerous or controversial prompts. ([View Highlight](https://read.readwise.io/read/01hbnn9mvp6sj0yp8z5aa8mbzb))
- **Hype**
  A central problem with public discussion of AI, according to a popular school of thought, is the role of hype—or the tendency of AI labs to mislead the public by [exaggerating the capabilities](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks) of their models, [anthropomorphizing](https://time.com/6238781/chatbot-chatgpt-ai-interview/) them, and [stoking fears](https://www.latimes.com/business/technology/story/2023-03-31/column-afraid-of-ai-the-startups-selling-it-want-you-to-be) about an AI apocalypse. ([View Highlight](https://read.readwise.io/read/01hbnnaj26pggh4q8yb6q6xpbj))
- **Paperclips**
  The innocuous paperclip has taken on outsized meaning in some sections of the AI safety community. It is the subject of *the paperclip maximizer,* an influential thought experiment about the existential risk that AI may pose to humanity. ([View Highlight](https://read.readwise.io/read/01hbnnbw723v2qww9skzdh8xmc))
- **Red teaming**
  Red-teaming is a method for stress-testing AI systems before they are publicly deployed. Groups of professionals (“red teams”) purposely attempt to make an AI behave in undesirable ways, to test how systems could go wrong in public. Their findings, if they are followed, can help tech companies to address problems before launch. ([View Highlight](https://read.readwise.io/read/01hbnncbnr46751kqgaa8jm1a3))
